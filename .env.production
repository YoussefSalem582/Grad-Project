# =================================================
# EmoSense App - Production Environment
# =================================================
#
# Configuration optimized for production deployment:
# - Secure production backend
# - Minimal logging for performance
# - No mock data for real user experience
# - Production-grade timeouts and cache settings
#
# SECURITY WARNING:
# Never commit real production API keys to version control!
# Use secure environment variable injection or secret management.
#

# =================================================
# Production API Configuration
# =================================================

# Render Production Backend URL
# EmoSense API deployed on Render with full AI capabilities
API_BASE_URL=https://emosense-production-api.onrender.com

# API key for production (optional for public endpoints)
# The backend is configured to allow public access for demo purposes
API_KEY=emosense-render-production

# Extended timeout for AI processing and Render cold starts
API_TIMEOUT=60000

# =================================================
# Production Environment Settings
# =================================================

ENVIRONMENT=production

# Disable debug mode in production for security and performance
DEBUG_MODE=false

# =================================================
# Production Feature Flags
# =================================================

# No mock data in production - users need real functionality
ENABLE_MOCK_DATA=false

# Minimal logging in production for performance
# Enable only for debugging production issues
ENABLE_LOGGING=false

# Analytics typically enabled in production for insights
ENABLE_ANALYTICS=true

# =================================================
# Production Performance Settings
# =================================================

# Standard cache timeout for production
CACHE_TIMEOUT=3600

# Full cache size for production performance
MAX_CACHE_SIZE=104857600

# Production-grade timeouts optimized for Render and AI processing
# Extended for cold starts and heavy model inference
CONNECT_TIMEOUT=60000
RECEIVE_TIMEOUT=120000
